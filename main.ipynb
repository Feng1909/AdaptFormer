{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptFormer\n",
    "\n",
    "论文地址：https://arxiv.org/abs/2205.13535\n",
    "\n",
    "## 简介：\n",
    "\n",
    "港大，腾讯AI实验室，港中文贡献的文章：AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition. 研究人员认为最新的transformer文章做的是**same network with task-specific weight**工作，用的是同样的网络，但是对每个下游任务都要fine-tune模型，这样的模型是不可拓展的，每搞一个数据集就要在上边fully finetune, 尤其是现在像ViT-G/14这样有18亿参数的大模型，训练时的算力和存储负担很重。所以他们要搞**same network with almost same weights**, 不仅网络要一样，应用到下游任务，权重也尽可能一样。只需要训练很少的参数，其他大部分参数是固定的，这些固定的参数就可以跨任务共享。\n",
    "\n",
    "要做这件事需要构建一种高效的pileline去适配预训练模型到许多下游任务，他们的工作更像**VPT** (Visual Prompt Tuning)，VPT在patch embedding那里增加可学习的参数同时冻结整个主干只finetuen embedding部分，但本项目所作的工作能够大大超越VPT，如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f76529af9d20462d8f0ba44d48a15da578875da0808a47adb2c22863b4905f17)\n",
    "\n",
    "**AdaptFormer**方法在SSv2数据集上**全面打败**了**VPT**\n",
    "\n",
    "本文的方法和VPT**不同**的地方在于，**AdaptFormer**是加到Transformer的**MHSA**(multi-head self-attention layer)上：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c2c110235c8549cca3a79e92c774440a458afbca68f841b6902881da4c5fde38)\n",
    "\n",
    "\n",
    "下图为在各种数据集上本方法与VPT等方法的对比：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e967f3621daf4ca8853f72f5e4e584ef19bc846aa5e84118aabdce340ad4a934)\n",
    "\n",
    "\n",
    "最后文章希望可以激励更多研究者探索更加高效的fine-tuning方法到大型视觉模型上。\n",
    "\n",
    "## 数据集介绍：Cifar100\n",
    "\n",
    "链接：http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7baff8d84907478294ca778385fca688741d14db13d841c39f0125c41f0a0ac4)\n",
    "\n",
    "\n",
    "CIFAR100数据集有100个类。每个类有600张大小为32 × 32 32\\times 3232×32的彩色图像，其中500张作为训练集，100张作为测试集。\n",
    "\n",
    "## 数据集介绍：Cifar10\n",
    "\n",
    "链接：http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/15a8790a113d41418d6fc8563aeb4acd10da73b4b8c6488599fa9e7a01cc0833)\n",
    "\n",
    "**CIFAR-10**是一个更接近普适物体的彩色图像数据集。CIFAR-10 是由Hinton 的学生Alex Krizhevsky 和Ilya Sutskever 整理的一个用于识别普适物体的小型数据集。一共包含10 个类别的RGB彩色图片：**飞机**(airplane)、**汽车**(automobile)、**鸟类**(bird)、**猫**(cat)、**鹿**(deer)、**狗**(dog)、**蛙类**(frog)、马(horse)、**船**(ship)和**卡车**(truck).\n",
    "\n",
    "每个图片的尺寸为 $32\\times 32$，每个类别有**6000**个图像，数据集中一共有**50000**张训练图片和**10000**张测试图片。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import paddle.nn as nn\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "from paddle.utils.download import get_weights_path_from_url\n",
    "import pickle\n",
    "import numpy as np\n",
    "from paddle import callbacks\n",
    "from paddle.vision.transforms import (\n",
    "    ToTensor, RandomHorizontalFlip, RandomResizedCrop, SaturationTransform, Compose,\n",
    "    HueTransform, BrightnessTransform, ContrastTransform, RandomCrop, Normalize, RandomRotation, Resize\n",
    ")\n",
    "from paddle.vision.datasets import Cifar10, Cifar100\n",
    "from paddle.io import DataLoader\n",
    "from paddle.optimizer.lr import CosineAnnealingDecay, MultiStepDecay, LinearWarmup\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, Dropout, BatchNorm, AdaptiveAvgPool2D, AvgPool2D\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "\n",
    "IS_STOP_GRADIENT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.图像分块嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:34:50.134982Z",
     "iopub.status.busy": "2022-06-18T05:34:50.134155Z",
     "iopub.status.idle": "2022-06-18T05:34:50.141878Z",
     "shell.execute_reply": "2022-06-18T05:34:50.141372Z",
     "shell.execute_reply.started": "2022-06-18T05:34:50.134932Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 图像分块、Embedding\n",
    "class PatchEmbed(nn.Layer):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        # 原始大小为int，转为tuple，即：img_size原始输入224，变换后为[224,224]\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        # 图像块的个数\n",
    "        num_patches = (img_size[1] // patch_size[1]) * \\\n",
    "            (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        # kernel_size=块大小，即每个块输出一个值，类似每个块展平后使用相同的全连接层进行处理\n",
    "        # 输入维度为3，输出维度为块向量长度\n",
    "        # 与原文中：分块、展平、全连接降维保持一致\n",
    "        # 输出为[B, C, H, W]\n",
    "        self.proj = nn.Conv2D(\n",
    "            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            \"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        # [B, C, H, W] -> [B, C, H*W] ->[B, H*W, C]\n",
    "        x = self.proj(x).flatten(2).transpose((0, 2, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:34:57.617843Z",
     "iopub.status.busy": "2022-06-18T05:34:57.616792Z",
     "iopub.status.idle": "2022-06-18T05:34:57.625905Z",
     "shell.execute_reply": "2022-06-18T05:34:57.625364Z",
     "shell.execute_reply.started": "2022-06-18T05:34:57.617796Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads=8,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim**-0.5\n",
    "        # 计算 q,k,v 的转移矩阵\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias_attr=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        # 最终的线性层\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C = x.shape[1:]\n",
    "        # 线性变换\n",
    "        qkv = self.qkv(x).reshape((-1, N, 3, self.num_heads, C //\n",
    "                                   self.num_heads)).transpose((2, 0, 3, 1, 4))\n",
    "        # 分割 query key value\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        # Scaled Dot-Product Attention\n",
    "        # Matmul + Scale\n",
    "        attn = (q.matmul(k.transpose((0, 1, 3, 2)))) * self.scale\n",
    "        # SoftMax\n",
    "        attn = nn.functional.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        # Matmul\n",
    "        x = (attn.matmul(v)).transpose((0, 2, 1, 3)).reshape((-1, N, C))\n",
    "        # 线性变换\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:35:06.693131Z",
     "iopub.status.busy": "2022-06-18T05:35:06.692340Z",
     "iopub.status.idle": "2022-06-18T05:35:06.698966Z",
     "shell.execute_reply": "2022-06-18T05:35:06.698174Z",
     "shell.execute_reply.started": "2022-06-18T05:35:06.693095Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features=None,\n",
    "                 out_features=None,\n",
    "                 act_layer=nn.GELU,\n",
    "                 drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入层：线性变换\n",
    "        x = self.fc1(x)\n",
    "        # 应用激活函数\n",
    "        x = self.act(x)\n",
    "        # Dropout\n",
    "        x = self.drop(x)\n",
    "        # 输出层：线性变换\n",
    "        x = self.fc2(x)\n",
    "        # Dropout\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.基础模块\n",
    "基于上面实现的 Attention、MLP 和下面的 DropPath 模块就可以组合出 Vision Transformer 模型的一个基础模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:35:08.846529Z",
     "iopub.status.busy": "2022-06-18T05:35:08.845717Z",
     "iopub.status.idle": "2022-06-18T05:35:08.853537Z",
     "shell.execute_reply": "2022-06-18T05:35:08.852649Z",
     "shell.execute_reply.started": "2022-06-18T05:35:08.846481Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_path(x, drop_prob=0., training=False):\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = paddle.to_tensor(1 - drop_prob)\n",
    "    shape = (paddle.shape(x)[0], ) + (1, ) * (x.ndim - 1)\n",
    "    random_tensor = keep_prob + paddle.rand(shape, dtype=x.dtype)\n",
    "    random_tensor = paddle.floor(random_tensor)\n",
    "    output = x.divide(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Layer):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Block\n",
    "\n",
    "**AdaptFormer**网络在**Block**中进行了更改，**MLP层**并行了`Down` `Relu` `Up`三层，并通过一个可学习的参数**scale**进行相加\n",
    "\n",
    "`Paddle`中提供的`stop_gradient`函数有两个功能，对于输出的值，如：\n",
    "```\n",
    "x = self.norm(x)\n",
    "x.sotp_gradient = True\n",
    "```\n",
    "则在**此层之前**的所有参数均停止更新\n",
    "```\n",
    "x = self.norm(x)\n",
    "self.norm.stop_gradient = True\n",
    "```\n",
    "则只停止这**一层网络**的参数更新\n",
    "\n",
    "以上两种用法可以用以**冻结网络**  \n",
    "通过读取全局变量`IS_STOP_GRADIENT`决定是否冻结网络\n",
    "\n",
    "关于此API的说明在官方文档中较少，后续可以进行补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:35:10.749839Z",
     "iopub.status.busy": "2022-06-18T05:35:10.749548Z",
     "iopub.status.idle": "2022-06-18T05:35:10.764444Z",
     "shell.execute_reply": "2022-06-18T05:35:10.763720Z",
     "shell.execute_reply.started": "2022-06-18T05:35:10.749811Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop=0.,\n",
    "                 attn_drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer='nn.LayerNorm',\n",
    "                 epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.norm1 = eval(norm_layer)(dim, epsilon=epsilon)\n",
    "        # Multi-head Self-attention\n",
    "        self.attn = Attention(\n",
    "            dim,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            qk_scale=qk_scale,\n",
    "            attn_drop=attn_drop,\n",
    "            proj_drop=drop)\n",
    "        # DropPath\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else Identity()\n",
    "        self.norm2 = eval(norm_layer)(dim, epsilon=epsilon)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim,\n",
    "                       hidden_features=mlp_hidden_dim,\n",
    "                       act_layer=act_layer,\n",
    "                       drop=drop)\n",
    "        self.n_embd = 768\n",
    "        self.down_size = 64\n",
    "        self.down_proj = nn.Linear(self.n_embd, self.down_size)\n",
    "        self.non_linear_func = nn.ReLU()\n",
    "        self.up_proj = nn.Linear(self.down_size, self.n_embd)\n",
    "        self.scale = self.create_parameter(shape=(1, 1), default_initializer=nn.initializer.Constant(value=1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-head Self-attention， Add， LayerNorm\n",
    "        ###\n",
    "        # 设置是否训练参数\n",
    "        ###\n",
    "        self.norm1.stop_gradient = IS_STOP_GRADIENT\n",
    "        self.attn.stop_gradient = IS_STOP_GRADIENT\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        # Feed Forward， Add， LayerNorm\n",
    "        residual = x\n",
    "        ###\n",
    "        # 设置是否训练norm层参数\n",
    "        ###\n",
    "        self.norm2.stop_gradient = IS_STOP_GRADIENT\n",
    "        x = self.norm2(x)\n",
    "        ###\n",
    "        # 设置是否训练MLP层参数\n",
    "        ###\n",
    "        self.mlp.stop_gradient = IS_STOP_GRADIENT\n",
    "        \n",
    "        ###\n",
    "        # 以下几层为AdaptFormer改进的核心，迁移训练过程中参数不变\n",
    "        ###\n",
    "\n",
    "        down = self.down_proj(x)\n",
    "        down = self.non_linear_func(down)\n",
    "        down = nn.functional.dropout(down, p=0.1)\n",
    "        up = self.up_proj(down)\n",
    "        up = up * self.scale + self.mlp(x)\n",
    "        up = self.drop_path(up)\n",
    "        output = up + residual\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.参数初始化配置、独立的不进行任何操作的网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:35:13.111324Z",
     "iopub.status.busy": "2022-06-18T05:35:13.110512Z",
     "iopub.status.idle": "2022-06-18T05:35:13.116003Z",
     "shell.execute_reply": "2022-06-18T05:35:13.115487Z",
     "shell.execute_reply.started": "2022-06-18T05:35:13.111287Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 参数初始化配置\n",
    "trunc_normal_ = nn.initializer.TruncatedNormal(std=.02)\n",
    "zeros_ = nn.initializer.Constant(value=0.)\n",
    "ones_ = nn.initializer.Constant(value=1.)\n",
    "\n",
    "# 将输入 x 由 int 类型转为 tuple 类型\n",
    "def to_2tuple(x):\n",
    "    return tuple([x] * 2)\n",
    "\n",
    "# 定义一个什么操作都不进行的网络层\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.完整代码\n",
    "\n",
    "由于Cifar100数据集由$32\\times 32$的图像构成，**图像大小偏小**，故将ViT的`patch_size` 由**16调整为3**，能够提取图像更多的特征信息。  \n",
    "调整后模型在测试集上的准确率能够随epoch的增加**迅速上升**，并**减少**过拟合现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:35:14.245687Z",
     "iopub.status.busy": "2022-06-18T05:35:14.245378Z",
     "iopub.status.idle": "2022-06-18T05:35:14.259806Z",
     "shell.execute_reply": "2022-06-18T05:35:14.259275Z",
     "shell.execute_reply.started": "2022-06-18T05:35:14.245657Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 img_size=32,\n",
    "                 patch_size=3,\n",
    "                 in_chans=3,\n",
    "                 class_dim=100,\n",
    "                 embed_dim=768,\n",
    "                 depth=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_ratio=4,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop_rate=0.,\n",
    "                 attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.,\n",
    "                 norm_layer='nn.LayerNorm',\n",
    "                 epsilon=1e-5,\n",
    "                 **args):\n",
    "        super().__init__()\n",
    "        self.class_dim = class_dim\n",
    "\n",
    "        self.num_features = self.embed_dim = embed_dim\n",
    "        # 图片分块和降维，块大小为patch_size，最终块向量维度为768\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim)\n",
    "        # 分块数量\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        # 可学习的位置编码\n",
    "        self.pos_embed = self.create_parameter(\n",
    "            shape=(1, num_patches + 1, embed_dim), default_initializer=zeros_)\n",
    "        self.add_parameter(\"pos_embed\", self.pos_embed)\n",
    "        # 人为追加class token，并使用该向量进行分类预测\n",
    "        self.cls_token = self.create_parameter(\n",
    "            shape=(1, 1, embed_dim), default_initializer=zeros_)\n",
    "        self.add_parameter(\"cls_token\", self.cls_token)\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = np.linspace(0, drop_path_rate, depth)\n",
    "        # transformer\n",
    "        self.blocks = nn.LayerList([\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                qk_scale=qk_scale,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[i],\n",
    "                norm_layer=norm_layer,\n",
    "                epsilon=epsilon) for i in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.norm = eval(norm_layer)(embed_dim, epsilon=epsilon)\n",
    "\n",
    "        # Classifier head\n",
    "        self.head = nn.Linear(embed_dim,\n",
    "                              class_dim) if class_dim > 0 else Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed)\n",
    "        trunc_normal_(self.cls_token)\n",
    "        self.apply(self._init_weights)\n",
    "    # 参数初始化\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            zeros_(m.bias)\n",
    "            ones_(m.weight)\n",
    "    # 获取图像特征\n",
    "    def forward_features(self, x):\n",
    "        B = paddle.shape(x)[0]\n",
    "        # 将图片分块，并调整每个块向量的维度\n",
    "        x = self.patch_embed(x)\n",
    "        # 将class token与前面的分块进行拼接\n",
    "        cls_tokens = self.cls_token.expand((B, -1, -1))\n",
    "        x = paddle.concat((cls_tokens, x), axis=1)\n",
    "        # 将编码向量中加入位置编码\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        ###\n",
    "        # 设置是否冻结网络\n",
    "        ###\n",
    "\n",
    "        x.stop_gradient = IS_STOP_GRADIENT\n",
    "        \n",
    "        # 堆叠 transformer 结构\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        # LayerNorm\n",
    "        x = self.norm(x)\n",
    "        # 提取分类 tokens 的输出\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取图像特征\n",
    "        x = self.forward_features(x)\n",
    "        # 图像分类\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T05:36:06.600795Z",
     "iopub.status.busy": "2022-06-18T05:36:06.600032Z",
     "iopub.status.idle": "2022-06-18T05:36:06.741365Z",
     "shell.execute_reply": "2022-06-18T05:36:06.740525Z",
     "shell.execute_reply.started": "2022-06-18T05:36:06.600747Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-2       [[1, 3, 32, 32]]     [1, 768, 10, 10]       21,504     \n",
      " PatchEmbed-2     [[1, 3, 32, 32]]      [1, 100, 768]            0       \n",
      "  Dropout-38      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-26     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-74      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-39    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "   Linear-75      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-40      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-13     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-13     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-27     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-78      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-13        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "   Linear-79       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "   Linear-76      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-13       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-41      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Linear-77      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-13        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-13       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-28     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-80      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-42    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "   Linear-81      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-43      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-14     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-14     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-29     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-84      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-14        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "   Linear-85       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "   Linear-82      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-14       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-44      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Linear-83      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-14        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-14       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-30     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-86      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-45    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "   Linear-87      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-46      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-15     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-15     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-31     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-90      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-15        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "   Linear-91       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "   Linear-88      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-15       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-47      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Linear-89      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-15        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-15       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-32     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-92      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-48    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "   Linear-93      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-49      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-16     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-16     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-33     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-96      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-16        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "   Linear-97       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "   Linear-94      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-16       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-50      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Linear-95      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-16        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-16       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-34     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "   Linear-98      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-51    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "   Linear-99      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-52      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-17     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-17     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-35     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-102      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-17        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-103       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-100      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-17       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-53      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-101      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-17        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-17       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-36     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-104      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-54    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-105      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-55      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-18     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-18     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-37     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-108      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-18        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-109       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-106      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-18       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-56      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-107      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-18        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-18       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-38     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-110      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-57    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-111      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-58      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-19     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-19     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-39     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-114      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-19        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-115       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-112      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-19       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-59      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-113      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-19        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-19       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-40     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-116      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-60    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-117      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-61      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-20     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-20     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-41     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-120      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-20        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-121       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-118      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-20       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-62      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-119      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-20        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-20       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-42     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-122      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-63    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-123      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-64      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-21     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-21     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-43     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-126      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-21        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-127       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-124      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-21       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-65      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-125      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-21        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-21       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-44     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-128      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-66    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-129      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-67      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-22     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-22     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-45     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-132      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-22        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-133       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-130      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-22       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-68      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-131      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-22        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-22       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-46     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-134      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-69    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-135      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-70      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-23     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-23     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-47     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-138      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-23        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-139       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-136      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-23       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-71      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-137      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-23        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-23       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-48     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-140      [[1, 101, 768]]       [1, 101, 2304]       1,769,472   \n",
      "  Dropout-72    [[1, 12, 101, 101]]   [1, 12, 101, 101]          0       \n",
      "  Linear-141      [[1, 101, 768]]       [1, 101, 768]         590,592    \n",
      "  Dropout-73      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " Attention-24     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Identity-24     [[1, 101, 768]]       [1, 101, 768]            0       \n",
      " LayerNorm-49     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-144      [[1, 101, 768]]        [1, 101, 64]         49,216     \n",
      "    ReLU-24        [[1, 101, 64]]        [1, 101, 64]            0       \n",
      "  Linear-145       [[1, 101, 64]]       [1, 101, 768]         49,920     \n",
      "  Linear-142      [[1, 101, 768]]       [1, 101, 3072]       2,362,368   \n",
      "    GELU-24       [[1, 101, 3072]]      [1, 101, 3072]           0       \n",
      "  Dropout-74      [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "  Linear-143      [[1, 101, 3072]]      [1, 101, 768]        2,360,064   \n",
      "    Mlp-24        [[1, 101, 768]]       [1, 101, 768]            0       \n",
      "   Block-24       [[1, 101, 768]]       [1, 101, 768]            1       \n",
      " LayerNorm-50     [[1, 101, 768]]       [1, 101, 768]          1,536     \n",
      "  Linear-146         [[1, 768]]            [1, 100]           76,900     \n",
      "===========================================================================\n",
      "Total params: 86,316,400\n",
      "Trainable params: 86,316,400\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 170.98\n",
      "Params size (MB): 329.27\n",
      "Estimated Total Size (MB): 500.26\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 86316400, 'trainable_params': 86316400}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "vit = VisionTransformer()\n",
    "paddle.summary(vit, (1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-12T16:24:40.576598Z",
     "iopub.status.busy": "2022-06-12T16:24:40.575870Z",
     "iopub.status.idle": "2022-06-12T16:24:40.581309Z",
     "shell.execute_reply": "2022-06-12T16:24:40.580783Z",
     "shell.execute_reply.started": "2022-06-12T16:24:40.576564Z"
    },
    "tags": []
   },
   "source": [
    "### 9.自定义数据集处理方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T12:57:51.119736Z",
     "iopub.status.busy": "2022-06-17T12:57:51.119498Z",
     "iopub.status.idle": "2022-06-17T12:57:51.131776Z",
     "shell.execute_reply": "2022-06-17T12:57:51.131038Z",
     "shell.execute_reply.started": "2022-06-17T12:57:51.119709Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToArray(object):\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = np.transpose(img, [2, 0, 1])\n",
    "        img = img / 255.\n",
    "        return img.astype('float32')\n",
    "\n",
    "class RandomApply(object):\n",
    "    def __init__(self, transform, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.p < random.random():\n",
    "            return img\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "                                                                                                                    \n",
    "class LRSchedulerM(callbacks.LRScheduler):                                                                                                           \n",
    "    def __init__(self, by_step=False, by_epoch=True, warm_up=True):                                                                                                \n",
    "        super().__init__(by_step, by_epoch)                                                                                                                          \n",
    "        assert by_step ^ warm_up\n",
    "        self.warm_up = warm_up\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.by_epoch and not self.warm_up:\n",
    "            if self.model._optimizer and hasattr(\n",
    "                self.model._optimizer, '_learning_rate') and isinstance(\n",
    "                    self.model._optimizer._learning_rate, paddle.optimizer.lr.LRScheduler):                                                                                         \n",
    "                self.model._optimizer._learning_rate.step()                                                                                          \n",
    "                                                                                                                                                     \n",
    "    def on_train_batch_end(self, step, logs=None):                                                                                                   \n",
    "        if self.by_step or self.warm_up:                                                                                                                             \n",
    "            if self.model._optimizer and hasattr(\n",
    "                self.model._optimizer, '_learning_rate') and isinstance(\n",
    "                    self.model._optimizer._learning_rate, paddle.optimizer.lr.LRScheduler):                                                                                         \n",
    "                self.model._optimizer._learning_rate.step()\n",
    "            if self.model._optimizer._learning_rate.last_epoch >= self.model._optimizer._learning_rate.warmup_steps:\n",
    "                self.warm_up = False\n",
    "\n",
    "def _on_train_batch_end(self, step, logs=None):\n",
    "    logs = logs or {}\n",
    "    logs['lr'] = self.model._optimizer.get_lr()\n",
    "    self.train_step += 1\n",
    "    if self._is_write():\n",
    "        self._updates(logs, 'train')\n",
    "\n",
    "def _on_train_begin(self, logs=None):\n",
    "    self.epochs = self.params['epochs']\n",
    "    assert self.epochs\n",
    "    self.train_metrics = self.params['metrics'] + ['lr']\n",
    "    assert self.train_metrics\n",
    "    self._is_fit = True\n",
    "    self.train_step = 0\n",
    "\n",
    "callbacks.VisualDL.on_train_batch_end = _on_train_batch_end\n",
    "callbacks.VisualDL.on_train_begin = _on_train_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.模型实验\n",
    "\n",
    "由于**PaddleClas**提供的**Vision Transformer**网络结构名称与本项目的网络名称定义不同，故**无法使用官方的预训练模型**\n",
    "\n",
    "本次试验尝试通过在**Cifar100**数据集获取预训练模型，再迁移至**Cifar10**数据集，通过**比较冻结网络与不冻结网络**的`Acc Top-1`区别，探究**AdaptFormer**网络的可行性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cifar100数据集训练模型： AdaptFormer_BaseModel\n",
    "\n",
    "训练参数为：\n",
    "* Epoch = 80\n",
    "* learning_rate = 0.01\n",
    "* weight_decay = 5e-4\n",
    "* momentum = 0.9\n",
    "* batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = paddle.Model(VisionTransformer(class_dim=100))\n",
    "# 加载checkpoint\n",
    "# model.load('output/AdaptFormer/80.pdparams', skip_mismatch=True)\n",
    "MAX_EPOCH = 80\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "IS_STOP_GRADIENT = False\n",
    "\n",
    "CIFAR_MEAN = [0.5071, 0.4865, 0.4409]\n",
    "CIFAR_STD = [0.1942, 0.1918, 0.1958]\n",
    "DATA_FILE = None\n",
    "\n",
    "model.prepare(\n",
    "    paddle.optimizer.Momentum(\n",
    "        learning_rate=LinearWarmup(CosineAnnealingDecay(LR, MAX_EPOCH), 2000, 0., LR),\n",
    "        momentum=MOMENTUM,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=WEIGHT_DECAY),\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    paddle.metric.Accuracy(topk=(1,5)))\n",
    "\n",
    "# 定义数据集增强方式\n",
    "transforms = Compose([\n",
    "    RandomCrop(32, padding=4),\n",
    "    RandomApply(BrightnessTransform(0.1)),\n",
    "    RandomApply(ContrastTransform(0.1)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomRotation(15),\n",
    "    ToArray(),\n",
    "    Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "    # Resize(size=72)\n",
    "])\n",
    "val_transforms = Compose([ToArray(), Normalize(CIFAR_MEAN, CIFAR_STD)])\n",
    "\n",
    "# 加载训练和测试数据集\n",
    "train_set = Cifar100(DATA_FILE, mode='train', transform=transforms)\n",
    "test_set = Cifar100(DATA_FILE, mode='test', transform=val_transforms)\n",
    "\n",
    "# 定义保存方式和训练可视化\n",
    "checkpoint_callback = paddle.callbacks.ModelCheckpoint(save_freq=20, save_dir='output/AdaptFormer_BaseModel')\n",
    "callbacks = [LRSchedulerM(),checkpoint_callback, callbacks.VisualDL('vis_logs/AdaptFormer_BaseModel.log')]\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    train_set,\n",
    "    test_set,\n",
    "    epochs=MAX_EPOCH, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    verbose=1, \n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过80轮的迭代，训练结果如图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9fe33b55eb0e4bb1a09a9da0b91cb45e083c50c76c794bd9b2ad1c963a70df26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cifar10数据集迁移模型实验\n",
    "\n",
    "训练参数：\n",
    "* Epoch = 10\n",
    "* learning_rate = 0.01\n",
    "* weight_decay = 5e-4\n",
    "* momentum = 0.9\n",
    "* batch_size = 128\n",
    "* IS_STOP_GRADIENT = True (实验组)\n",
    "* IS_STOP_GRADIENT = False (对照组)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = paddle.Model(VisionTransformer(class_dim=10))\r\n",
    "# 加载checkpoint\r\n",
    "model.load('output/AdaptFormer_BaseModel/80.pdparams', skip_mismatch=True)\r\n",
    "MAX_EPOCH = 10\r\n",
    "LR = 0.01\r\n",
    "WEIGHT_DECAY = 5e-4\r\n",
    "MOMENTUM = 0.9\r\n",
    "BATCH_SIZE = 128\r\n",
    "\r\n",
    "IS_STOP_GRADIENT = True    # 实验组\r\n",
    "IS_STOP_GRADIENT = False   # 对照组\r\n",
    "\r\n",
    "CIFAR_MEAN = [0.5071, 0.4865, 0.4409]\r\n",
    "CIFAR_STD = [0.1942, 0.1918, 0.1958]\r\n",
    "DATA_FILE = None\r\n",
    "\r\n",
    "model.prepare(\r\n",
    "    paddle.optimizer.Momentum(\r\n",
    "        learning_rate=LinearWarmup(CosineAnnealingDecay(LR, MAX_EPOCH), 2000, 0., LR),\r\n",
    "        momentum=MOMENTUM,\r\n",
    "        parameters=model.parameters(),\r\n",
    "        weight_decay=WEIGHT_DECAY),\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    paddle.metric.Accuracy(topk=(1,5)))\r\n",
    "\r\n",
    "# 定义数据集增强方式\r\n",
    "transforms = Compose([\r\n",
    "    RandomCrop(32, padding=4),\r\n",
    "    RandomApply(BrightnessTransform(0.1)),\r\n",
    "    RandomApply(ContrastTransform(0.1)),\r\n",
    "    RandomHorizontalFlip(),\r\n",
    "    RandomRotation(15),\r\n",
    "    ToArray(),\r\n",
    "    Normalize(CIFAR_MEAN, CIFAR_STD),\r\n",
    "    # Resize(size=72)\r\n",
    "])\r\n",
    "val_transforms = Compose([ToArray(), Normalize(CIFAR_MEAN, CIFAR_STD)])\r\n",
    "\r\n",
    "# 加载训练和测试数据集\r\n",
    "train_set = Cifar10(DATA_FILE, mode='train', transform=transforms)\r\n",
    "test_set = Cifar10(DATA_FILE, mode='test', transform=val_transforms)\r\n",
    "\r\n",
    "# 定义保存方式和训练可视化\r\n",
    "checkpoint_callback = paddle.callbacks.ModelCheckpoint(save_freq=20, save_dir='output/AdaptFormer_BaseModel')\r\n",
    "callbacks = [LRSchedulerM(),checkpoint_callback, callbacks.VisualDL('vis_logs/AdaptFormer_BaseModel.log')]\r\n",
    "\r\n",
    "# 训练模型\r\n",
    "model.fit(\r\n",
    "    train_set,\r\n",
    "    test_set,\r\n",
    "    epochs=MAX_EPOCH, \r\n",
    "    batch_size=BATCH_SIZE,\r\n",
    "    shuffle=True,\r\n",
    "    num_workers=0,\r\n",
    "    verbose=1, \r\n",
    "    callbacks=callbacks,\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验结果  \n",
    "\n",
    "**冻结网络迁移训练(左图)：**  \n",
    "训练参数量：**4.56 MB**  \n",
    "8个Epoch后`Acc Top-1`：**0.7784**  \n",
    "\n",
    "**不冻结网络迁移训练(右图)：**  \n",
    "\n",
    "训练参数量：**329.27 MB**\n",
    "\n",
    "10个Epoech后`Acc Top-1`：**0.7662**\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/a927297b4707434bb68e979123ede7d578593846e8324707a02b7e2cd578489c\" width=\"300\" height=\"120\"/><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7a21fa9996d9448bb055f67f4dd677255a4d9d9848bd41a88fe954f041008def\" width=\"300\" height=\"120\"/>\n",
    "\n",
    "\n",
    "**冻结后网络**需要训练的参数仅为完整训练参数的**1.38%** ，但是模型的准确率在**减少**两个Epoch的情况下相对于完整训练反而**增加**了一个百分点，由此可以体现**AdaptFormer**网络在迁移学习中的优越性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "本次复现任务是百度AI达人项目的一个课题，需要对MLP的运行逻辑部分进行修改，并设计实验进行验证。本次复现主要参考了github上作者的复现代码，并改写为PaddlePaddle框架代码，特别感谢百度李老师的指导！\n",
    "\n",
    "本项目通过**冻结部分网络参数**，验证AdaptFormer网络的有效性。主要依靠PaddlePaddle的`stop_gradient` **API** 实现冻结功能，对模型参数进行迁移。本次复现的效果与原文一致，效果直观且结果成功。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
